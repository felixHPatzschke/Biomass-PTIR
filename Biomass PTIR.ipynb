{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82656ffa",
   "metadata": {},
   "source": [
    "# PTIR Data from Harvested Biomass Samples\n",
    "## Setup\n",
    "### Library Imports\n",
    "#### Maths and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import sklearn.decomposition as decomp\n",
    "import sklearn.cluster as cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb258c",
   "metadata": {},
   "source": [
    "#### I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9864315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import yaml\n",
    "import h5py\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0d0c5",
   "metadata": {},
   "source": [
    "#### PTIR dataset handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ptirtools as ptir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3461ca",
   "metadata": {},
   "source": [
    "### Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f633ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = None\n",
    "with open(\"config.yml\", 'r') as handle:\n",
    "    CONFIG = yaml.safe_load(handle)\n",
    "assert CONFIG is not None , \"Failed to load config file.\"\n",
    "pprint.pp(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c221b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = None\n",
    "with open(\"gruvbox_colors.yml\", 'r') as handle:\n",
    "    COLORS = yaml.safe_load(handle)\n",
    "assert COLORS is not None , \"Failed to load config file.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1bd7b",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "### Search for Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_NAMES = glob.glob(f\"{CONFIG['directories']['ptirfiles']}/*.ptir\")\n",
    "INPUT_FILE_NAMES = [ f.split(\"/\")[-1] for f in INPUT_FILE_NAMES ]\n",
    "INPUT_FILE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f382b7",
   "metadata": {},
   "source": [
    "### Load Relevant Data\n",
    "#### Accumulate from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = {}\n",
    "\n",
    "for ifn in INPUT_FILE_NAMES:\n",
    "    h5file = h5py.File(f\"{CONFIG['directories']['ptirfiles']}/{ifn}\", 'r')\n",
    "    DATA[ifn] = ptir.h5Group2Dict( h5file, h5file, [] )\n",
    "    h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908efac",
   "metadata": {},
   "source": [
    "#### Extract Image and Spectral Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES = { fn:dict(index=int(fn[1]), images=[], spectra=[]) for i,fn in enumerate(INPUT_FILE_NAMES) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename,data in DATA.items():\n",
    "    for img_key, image in data[\"Images\"].items():\n",
    "        image_data = image['data']\n",
    "        metadata = image['meta']\n",
    "\n",
    "        SAMPLES[filename][\"images\"].append( dict(data=image_data, extent=ptir.image_extent(metadata)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf95887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename,data in DATA.items():\n",
    "    for meas_key, measurement in data.items():\n",
    "        if meas_key.startswith(\"Measurement_\"):\n",
    "            if not bool(measurement['attribs']['IsBackground']):\n",
    "                wavenumbers = measurement['Spectroscopic_Values']['data']\n",
    "                channels = [ y['Raw_Data']['data'] for ch,y in measurement.items() if ch.startswith(\"Channel_\") ]\n",
    "                if len(channels) > 0:\n",
    "                    SAMPLES[filename]['spectra'].append(\n",
    "                        dict( \n",
    "                            position=tuple( measurement['attribs'][f\"Location{X}\"][0] for X in \"XYZ\" ),\n",
    "                            wavenumbers=np.array(wavenumbers[0]), \n",
    "                            channels=np.array([channel[0] for channel in channels]),\n",
    "                        )\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9febb",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn,data in SAMPLES.items():\n",
    "    fig = plt.figure( figsize=(9,3) , dpi=200 )\n",
    "    gs = fig.add_gridspec( 1, 2, width_ratios=[1,2.5] )\n",
    "    \n",
    "    ax = fig.add_subplot( gs[1] )\n",
    "\n",
    "    positions = np.zeros( (2, len(data['spectra'])) )\n",
    "    accumulator = np.zeros( (len(data['spectra']), *data['spectra'][0]['channels'][0].shape), dtype=np.complex128 )\n",
    "    wavenumbers = data['spectra'][0]['wavenumbers']\n",
    "    ### TODO: check that the domains are the same\n",
    "    for ispec,spectrum in enumerate(data['spectra']):\n",
    "        _optir, _phase, _x, _y = spectrum['channels']\n",
    "        _amplitude = _x + 1j*_y\n",
    "        accumulator[ispec] += _amplitude\n",
    "        #ax.plot( wavenumbers, np.abs(_amplitude), color=COLORS['normal']['yellow'], alpha=0.1 )\n",
    "        positions[0,ispec] = spectrum['position'][0]\n",
    "        positions[1,ispec] = spectrum['position'][1]\n",
    "    ax.plot( wavenumbers, np.abs(np.mean(accumulator, axis=0)), color=COLORS['normal']['red'], label='avg. amplitude' )\n",
    "    ax.plot( [], [], color=COLORS['normal']['blue'], label='avg. phase' )\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot( wavenumbers, np.unwrap(np.angle(np.mean(accumulator, axis=0)[::-1]))[::-1], color=COLORS['normal']['blue'] )\n",
    "    ax.set_xlabel(\"Wavenumber [cm$^{-1}$]\")\n",
    "    ax.set_ylabel(\"Amplitude [a.u.]\", color=COLORS['normal']['red'])\n",
    "    ax.set_yticks([0])\n",
    "    ax2.set_ylabel(\"Phase [rad]\", color=COLORS['normal']['blue'])\n",
    "    ax.tick_params(axis='y', labelcolor=COLORS['normal']['red'])\n",
    "    ax2.tick_params(axis='y', labelcolor=COLORS['normal']['blue'])\n",
    "    ax.set_ylim(ymax=1.5*np.max(np.abs(np.mean(accumulator, axis=0))), ymin=-0.15*np.max(np.abs(np.mean(accumulator, axis=0))))\n",
    "\n",
    "    ax.set_xlim(xmin=np.min(wavenumbers), xmax=np.max(wavenumbers))\n",
    "    ax.axhline( 0, c=COLORS['normal']['red'], lw=0.5, ls='--' )\n",
    "    ax.set_title( f\"{fn[:-len('.ptir')]} average (n={len(accumulator)})\" )\n",
    "    ax.invert_xaxis()\n",
    "    #ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    xmin,ymin = np.min(positions,axis=1)\n",
    "    xmax,ymax = np.max(positions,axis=1)\n",
    "\n",
    "    ax = fig.add_subplot( gs[0] )\n",
    "    for image in data[\"images\"]:\n",
    "        ax.imshow( image[\"data\"], extent=image['extent'] )\n",
    "    \n",
    "    ax.fill( \n",
    "        [xmin, xmax, xmax, xmin],\n",
    "        [ymin, ymin, ymax, ymax],\n",
    "        fill=False,\n",
    "        color=COLORS['normal']['yellow'],\n",
    "        lw=2\n",
    "    )\n",
    "    ax.text(\n",
    "        0.5*(xmin+xmax), ymin,\n",
    "        f\"{xmax-xmin:.0f}µm\",\n",
    "        size=8, color='k', va='center', ha='center', backgroundcolor=COLORS['normal']['yellow']\n",
    "    )\n",
    "    ax.text(\n",
    "        xmin, 0.5*(ymin+ymax), \n",
    "        f\"{ymax-ymin:.0f}µm\",\n",
    "        size=8, color='k', va='center', ha='center', backgroundcolor=COLORS['normal']['yellow'], rotation=90\n",
    "    )\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    fig.patch.set_alpha(0.0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig(f\"{CONFIG['directories']['output']}/{fn[:-len('.ptir')]} average.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f37a3",
   "metadata": {},
   "source": [
    "## Dimension Reduction\n",
    "We are dealing with quite a large amount of data. Even if the spectra were perfectly precise (which they definitely aren't), to make any statements about the samples, we must somehow reduce the number of variables we're analyzing. \n",
    "\n",
    "A basic way to do that is **Singular Value Decomposition (SVD)**. To implement that, we would write all the spectra into a huge matrix. As additional components, we would include any kind of classification we can tag the spectra with. That is, for instance, the sample it appears in (but not the index of the sample as a value, but a bitmap whose size is the number of samples and all bits are zero except the one at the position that corresponds to the sample) and the values of the RGB fluorescence channels.\n",
    "\n",
    "### Arrange all spectra into one data structure\n",
    "\n",
    "We'll allocate an array with dimensions\n",
    "- number of spectra\n",
    "- (number of samples) + 3 (number of wide field image channels) + (number of manually determined classes) + (number of wavenumbers)\n",
    "\n",
    "and then start slicing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = {\n",
    "    'samples' : 0,\n",
    "    'widefieldchannels' : 3,\n",
    "    'classes' : 0,\n",
    "    'spectra' : 0,\n",
    "}\n",
    "for fn,data in SAMPLES.items():\n",
    "    NUM['samples'] = max( NUM['samples'] , int(fn[1])+1 )\n",
    "    NUM['spectra'] += len(data['spectra'])\n",
    "WAVENUMBERS = np.copy(data['spectra'][0]['wavenumbers'])\n",
    "NUM['wavenumbers'] = len(WAVENUMBERS)\n",
    "\n",
    "OFFSET = { key:sum( [ NUM[key2] for key2 in list(NUM.keys())[:list(NUM.keys()).index(key)] ] ) for key in NUM }\n",
    "del OFFSET['wavenumbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = np.zeros( ( NUM['spectra'] , sum([NUM[key] for key in NUM.keys() if key != 'spectra']) ) , dtype=np.complex128 )\n",
    "SORTED_FILES = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_dataset = 0\n",
    "\n",
    "for fn,data in SAMPLES.items():\n",
    "    idx_file = int(fn[1])\n",
    "    SORTED_FILES[idx_file] = fn[:-len('.ptir')]\n",
    "\n",
    "    for ispec,spectrum in enumerate(data['spectra']):\n",
    "        DATASET[idx_dataset,idx_file] = 1.0\n",
    "        _optir, _phase, _x, _y = spectrum['channels']\n",
    "        #DATASET[idx_dataset,OFFSET['spectra']:] += _x + 1j*_y\n",
    "        ### analyse only amplitude, not complex phase\n",
    "        DATASET[idx_dataset,OFFSET['spectra']:] += np.sqrt( _x**2 + _y**2 )\n",
    "\n",
    "        idx_dataset += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340fb5ad",
   "metadata": {},
   "source": [
    "To later accurately label any plots, let's keep track of which column corresponds to which feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec54fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = [\"None\"] + [ SORTED_FILES[i] for i in sorted(list(SORTED_FILES.keys())) ]+[ \"R\", \"G\", \"B\" ]\n",
    "for i in range(len(FEATURE_NAMES)):\n",
    "    if FEATURE_NAMES[i][0] == '[':\n",
    "        FEATURE_NAMES[i] = \"Sample \" + FEATURE_NAMES[i].split(']')[0] + \"]\"\n",
    "for i,f in enumerate(FEATURE_NAMES): print(f\"{i:>02d} : {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa4d13",
   "metadata": {},
   "source": [
    "Classes and wide field colours remain to be done...\n",
    "\n",
    "### Unguided Singular Value Decomposition\n",
    "Since `sklearn.decomposition.PCA` does not support complex-valued input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAT, SIGMA, VADJ = sp.linalg.svd( DATASET, full_matrices=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634eef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_PCA = { 'explained_variance' : (SIGMA**2) / DATASET.shape[0] }\n",
    "MANUAL_PCA['explained_variance_ratio'] = MANUAL_PCA['explained_variance']/np.sum(MANUAL_PCA['explained_variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(4,3), dpi=100 )\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(\n",
    "    np.arange(len(MANUAL_PCA['explained_variance_ratio']))+1,\n",
    "    MANUAL_PCA['explained_variance_ratio'], \n",
    "    color=COLORS['normal']['blue'], marker='o'\n",
    ")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylim(ymin=1e-7, ymax=1)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlabel(\"SVD Component Index\")\n",
    "ax.set_ylabel(\"Explained Variance\")\n",
    "fig.patch.set_alpha(0.0)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567fa300",
   "metadata": {},
   "source": [
    "Apparently, the first 8 components are significant and, from then on, we have mostly noise over-fitting. So let's have a look at these 8 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e099a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 8\n",
    "SVDCOLORS = [ COLORS['normal'][c] for c in [\"yellow\",\"orange\",\"red\",\"purple\",\"blue\",\"aqua\",\"green\"] ]\n",
    "SVDCOLORS.insert(0,COLORS['light_to_dark'][4])\n",
    "SVDCOLORS.append(COLORS['normal']['gray'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a3b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "def ring_access(a:Iterable, i:int):\n",
    "    return a[i%len(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91909b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(12,6), dpi=100 )\n",
    "gs = fig.add_gridspec( 2, 2, width_ratios=[1,4], height_ratios=[3,2] )\n",
    "\n",
    "axes = [ \n",
    "    fig.add_subplot( gs[:,1] ), \n",
    "    fig.add_subplot( gs[0,0] ), \n",
    "    fig.add_subplot( gs[1,0] ), \n",
    "]\n",
    "\n",
    "y_offset_abs = 0\n",
    "\n",
    "for idx in range(CUTOFF)[::-1]:\n",
    "    component = VADJ[idx,OFFSET['spectra']:]\n",
    "    axes[0].plot( WAVENUMBERS, 1.25*np.abs(component)/np.max(np.abs(component)) + y_offset_abs, color=ring_access(SVDCOLORS, idx) )\n",
    "    axes[0].axhline( y_offset_abs, ls='--', lw=0.5, color=ring_access(SVDCOLORS, idx) )\n",
    "    axes[0].text(np.max(WAVENUMBERS), y_offset_abs-0.05, f\" Component {idx}\", va='top', ha='left', color=ring_access(SVDCOLORS, idx))\n",
    "    y_offset_abs += 1 # np.max(np.abs(component))\n",
    "\n",
    "axes[0].set_ylabel(\"Amplitude [a.u.]\")\n",
    "axes[0].set_yticks([])\n",
    "\n",
    "for ax in axes[:1]:\n",
    "    ax.set_xlim(xmin=np.min(WAVENUMBERS), xmax=np.max(WAVENUMBERS))\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_xlabel(\"Wavenumber [cm$^{-1}$]\")\n",
    "\n",
    "axes[1].imshow( np.abs(  VADJ[:CUTOFF,:OFFSET['spectra']]), cmap='magma' )\n",
    "\n",
    "for ax in axes[1:2]:\n",
    "    ax.set_ylabel(\"SVD Component\")\n",
    "    #ax.set_xlabel(\"Feature\")\n",
    "    ax.set_xticks(\n",
    "        ticks = list(range(len(FEATURE_NAMES))),\n",
    "        labels = FEATURE_NAMES,\n",
    "        rotation=90\n",
    "    )\n",
    "    ax.set_yticks( ticks = list(range(CUTOFF)) )\n",
    "\n",
    "#cutoff = 8\n",
    "pie = dict()\n",
    "pie['x'] = [ r for r in MANUAL_PCA['explained_variance_ratio'][:CUTOFF] ]\n",
    "pie['x'].append( np.sum( [ r for r in MANUAL_PCA['explained_variance_ratio'][CUTOFF:] ] ) )\n",
    "pie['colors'] = [ COLORS['bright'][c] for c in [\"yellow\",\"orange\",\"red\",\"purple\",\"blue\",\"aqua\",\"green\"] ]\n",
    "pie['colors'].insert(0,COLORS['light_to_dark'][4])\n",
    "pie['colors'].append(COLORS['normal']['gray'])\n",
    "pie['autopct'] = lambda pct: f\"{pct:.1f}%\" if pct > 10 else \"\"\n",
    "pie['textprops'] = dict( size=7 )\n",
    "pie['explode'] = np.cos( np.array(pie['x']) * 2*np.pi )*0.2\n",
    "\n",
    "wedges,texts,autotexts = axes[2].pie(**pie)\n",
    "\n",
    "# axes[2].legend(\n",
    "#     wedges, \n",
    "#     [f\"Component {i}\" for i in range(CUTOFF)]+[\"other components\"],\n",
    "#     loc=\"center left\",\n",
    "#     bbox_to_anchor=(1,0,0.5,1)\n",
    "# )\n",
    "axes[2].set_ylabel(\"Explained Variance\")\n",
    "\n",
    "fig.patch.set_alpha(0.0)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{CONFIG['directories']['output']}/../SVD_amplitude_components.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85648b",
   "metadata": {},
   "source": [
    "It appears, that the 8 principal components we see are just the average spectra of the 8 samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ebcc4",
   "metadata": {},
   "source": [
    "Another way would be to **fit a fixed number of Gaussians** to each individual spectrum and then try to correlate these to the classifications. Each Gaussian would have as parameters just magnitude and width. The central value would have to be pre-set to ensure comparability, though a small deviation parameter may be included, allowing the bell curve to shift a few wavenumbers. Central value, offset and width shall be real-valued, the amplitude may be complex-valued.\n",
    "\n",
    "### Decomposition by Peaks\n",
    "\n",
    "Likely locations where we would expect to find peaks and should thus start the gaussians for fitting at are...\n",
    "- $1650 \\, \\mathrm{cm}^{-1}:$ Amide-I band and water absorption peak\n",
    "- $1550 \\, \\mathrm{cm}^{-1}:$ Amide-II band\n",
    "- $1730 \\, \\mathrm{cm}^{-1}:$ C=O vibration band\n",
    "- $1470 \\, \\mathrm{cm}^{-1}:$ CH<sub>2</sub> scissoring\n",
    "- $1150 \\, \\mathrm{cm}^{-1}$\n",
    "- $1080 \\, \\mathrm{cm}^{-1}:$ PO<sub>4</sub> stretching\n",
    "- $1020 \\, \\mathrm{cm}^{-1}:$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIKELY_PEAKS = [ 1730, 1650, 1550, 1470, 1150, 1080, 1020 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaed03b",
   "metadata": {},
   "source": [
    "We'll attempt to find peaks in all recorded spectra..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc138f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEAKS = []\n",
    "PROMS = []\n",
    "WIDTHS = []\n",
    "\n",
    "for line in range(CUTOFF):\n",
    "    spectrum = np.abs( DATASET[line,OFFSET['spectra']:] )\n",
    "    #spectrum = np.abs( VADJ[line,OFFSET['spectra']:] )\n",
    "\n",
    "    peaks,props = sp.signal.find_peaks( \n",
    "        spectrum / np.max(spectrum),\n",
    "        prominence = 1e-3,\n",
    "        width=2.0\n",
    "    )\n",
    "    PEAKS.append(peaks)\n",
    "    PROMS.append(props['prominences']*np.max(spectrum))\n",
    "    WIDTHS.append(props['widths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fd9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(6,4), dpi=100 )\n",
    "gs = fig.add_gridspec( 1, 1 )\n",
    "\n",
    "ax = fig.add_subplot( gs[:,:] )\n",
    "\n",
    "idx_to_wavenumbers = np.mean(np.diff(WAVENUMBERS))\n",
    "\n",
    "i_comp = 0\n",
    "for peaks,proms,widths in zip(PEAKS,PROMS,WIDTHS):\n",
    "    ax.scatter(\n",
    "        WAVENUMBERS[peaks],\n",
    "        proms*widths,\n",
    "        color = COLORS['normal']['red'],\n",
    "        marker = 'o',\n",
    "        s=proms*widths*100\n",
    "    )\n",
    "    i_comp += 1\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel(\"Wavenumber [cm$^{-1}$]\")\n",
    "ax.set_ylabel(\"Peak Magnitude [a.u.]\")\n",
    "\n",
    "fig.patch.set_alpha(0.0)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{CONFIG['directories']['output']}/peak_magnitudes.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(6,6), dpi=100 )\n",
    "gs = fig.add_gridspec( 1, 1 )\n",
    "\n",
    "ax = fig.add_subplot( gs[:,:] )\n",
    "\n",
    "idx_to_wavenumbers = np.mean(np.diff(WAVENUMBERS))\n",
    "\n",
    "flatten = lambda xss : [x for xs in xss for x in xs]\n",
    "FLAT_PEAKS = np.array( flatten(PEAKS) )\n",
    "FLAT_PROMS = np.array( flatten(PROMS) )\n",
    "FLAT_WIDTHS = np.array( flatten(WIDTHS) )\n",
    "\n",
    "ax.scatter(\n",
    "    WAVENUMBERS[FLAT_PEAKS],\n",
    "    FLAT_WIDTHS,\n",
    "    c = FLAT_PROMS,\n",
    "    cmap = mpl.cm.Spectral_r,\n",
    "    marker = 'o', \n",
    "    s=FLAT_PROMS*FLAT_WIDTHS*400,\n",
    "    alpha=1.0, \n",
    ")\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel(\"Wavenumber [cm$^{-1}$]\")\n",
    "ax.set_ylabel(\"Peak Width [cm$^{-1}$]\")\n",
    "\n",
    "fig.patch.set_alpha(0.0)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6af81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{CONFIG['directories']['output']}/peak_widths_and_proms_log.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cb671",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_weights = FLAT_WIDTHS*FLAT_PROMS\n",
    "clustering_weights /= np.max(clustering_weights)\n",
    "clustering_weights *= 1000\n",
    "\n",
    "clustering_data = []\n",
    "for weight,peak,width,prom in zip(clustering_weights, FLAT_PEAKS, FLAT_WIDTHS, FLAT_PROMS):\n",
    "    for _ in range(int(max(1,weight))):\n",
    "        clustering_data.append( [ WAVENUMBERS[peak], width ] )\n",
    "clustering_data = np.array(clustering_data)\n",
    "\n",
    "clustering_norm = np.ones( ( clustering_data.shape[1] , ) )\n",
    "clustering_norm[1] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans = cluster.KMeans(n_clusters=17, random_state=0, n_init=\"auto\").fit( clustering_data / clustering_norm[None,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f570ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize=(8,5), dpi=100 )\n",
    "gs = fig.add_gridspec( 1, 1 )\n",
    "\n",
    "ax = fig.add_subplot( gs[:,:] )\n",
    "\n",
    "idx_to_wavenumbers = np.mean(np.diff(WAVENUMBERS))\n",
    "\n",
    "ax.scatter(\n",
    "    clustering_data[:,0],\n",
    "    clustering_data[:,1],\n",
    "    c = [ ring_access( SVDCOLORS[1:], l ) for l in kmeans.labels_ ],\n",
    "    marker = 'o', \n",
    "    #s=FLAT_PROMS*FLAT_WIDTHS*400,\n",
    "    alpha=1.0,\n",
    "    s=3 \n",
    ")\n",
    "\n",
    "for i,center in enumerate(kmeans.cluster_centers_):\n",
    "    ax.text(\n",
    "        *(center * clustering_norm), \n",
    "        f\"{center[0] * clustering_norm[0]:.0f}\",\n",
    "        ha='center', va='center_baseline', color=ring_access( SVDCOLORS[1:], i ), \n",
    "        bbox=dict(facecolor='w', alpha=0.666, edgecolor=ring_access( SVDCOLORS[1:], i ), boxstyle='circle')\n",
    "    )\n",
    "\n",
    "ax.invert_xaxis()\n",
    "ax.set_xlabel(\"Wavenumber [cm$^{-1}$]\")\n",
    "ax.set_ylabel(\"Peak Width [cm$^{-1}$]\")\n",
    "\n",
    "ax.set_xticks( np.arange(1000,1900,100), minor=False )\n",
    "ax.set_xticks( np.arange(950,1900,50), minor=True )\n",
    "\n",
    "fig.patch.set_alpha(0.0)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{CONFIG['directories']['output']}/peak_clusters.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wavenumber,widthx10 in kmeans.cluster_centers_[np.argsort(kmeans.cluster_centers_[:,1])][::-1]:\n",
    "    print(f\"- {wavenumber:.0f} cm⁻¹ ± {widthx10/10:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b64266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
